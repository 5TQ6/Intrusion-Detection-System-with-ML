{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b32b5f02",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c896b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import sys \n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from utils import clean_database, perform_voting_feature_selection, perform_transformation_feature_selection, perform_voting_feature_transformation\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Choose the model RF/MLP, you should also change the eval_model in utils.py to the same model\n",
    "model_name = 'RF'\n",
    "preprocessing_dir = os.path.join('figures','preprocessing', model_name)\n",
    "db_path = os.path.join('..', 'data', 'datasets', '5G NIDD', 'Combined.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffc40c1",
   "metadata": {},
   "source": [
    "# Data cleaning and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c08fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, output_encoder = clean_database(db_path, preprocessing_dir, do_scale=True, fix_skewness=False)\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f7e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of remaining features\n",
    "print(f\"Remaining features count: {X_train.shape[1]}\")\n",
    "\n",
    "# Print the list of remaining feature names\n",
    "print(\"Remaining features list:\")\n",
    "print(X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e76369",
   "metadata": {},
   "source": [
    "# Feature selection methods loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eddfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_features_list = [35, 30, 25, 20, 15, 10, 5, 1]\n",
    "# Helper to save DataFrame or Numpy array to CSV\n",
    "def save_to_csv(data, full_path):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        data.to_csv(full_path, index=False)\n",
    "    else:\n",
    "        # Convert numpy array to DataFrame\n",
    "        pd.DataFrame(data).to_csv(full_path, index=False)\n",
    "        \n",
    "# 1. Loop through each configuration\n",
    "for n in n_features_list:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"STARTING PIPELINE: {n} FEATURES\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # --- A. Setup Version and Directory ---\n",
    "    version = f\"{n}F\"\n",
    "    save_dir = os.path.join('..', 'data frames', 'main', model_name, f'{n} features')\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        print(f\"[Setup] Created directory: {save_dir}\")\n",
    "    else:\n",
    "        print(f\"[Setup] Directory exists: {save_dir}\")\n",
    "\n",
    "    # --- B. Perform Feature Selection ---\n",
    "    # We pass the ORIGINAL full datasets (X_train, etc.)\n",
    "    print(f\"[Step 1] Running Voting Feature Selection...\")\n",
    "    selected_features, comparison_results = perform_voting_feature_selection(\n",
    "        X_train, y_train, X_val, y_val, \n",
    "        n_features=n, \n",
    "        sample_size=None, \n",
    "        file_path=preprocessing_dir, # Keeps selection plots in the main preprocessing folder\n",
    "        version=version\n",
    "    )\n",
    "    \n",
    "    # Save the list of selected features to a text file\n",
    "    with open(os.path.join(save_dir, f'selected_features_{version}.txt'), 'w') as f:\n",
    "        f.write('\\n'.join(selected_features))\n",
    "\n",
    "    # --- C. Subset the Data ---\n",
    "    # CRITICAL: We create COPIES (sub) instead of overwriting X_train.\n",
    "    # This preserves the original X_train for the next iteration of the loop.\n",
    "    print(f\"[Step 2] Dropping non-selected features...\")\n",
    "    X_train_sub = X_train[selected_features].copy()\n",
    "    X_val_sub = X_val[selected_features].copy()\n",
    "    X_test_sub = X_test[selected_features].copy()\n",
    "\n",
    "    # --- D. Save the Dataframes (Skipping Preprocessing/Sampling) ---\n",
    "    print(f\"[Step 3] Saving dataframes to {save_dir} (Skipping Sampling)...\")\n",
    "    \n",
    "    save_to_csv(X_train_sub, os.path.join(save_dir, f'X_train_{version}.csv'))\n",
    "    save_to_csv(X_val_sub, os.path.join(save_dir, f'X_val_{version}.csv'))\n",
    "    save_to_csv(X_test_sub, os.path.join(save_dir, f'X_test_{version}.csv'))\n",
    "    save_to_csv(y_train, os.path.join(save_dir, f'y_train_{version}.csv'))\n",
    "    save_to_csv(y_val, os.path.join(save_dir, f'y_val_{version}.csv'))\n",
    "    save_to_csv(y_test, os.path.join(save_dir, f'y_test_{version}.csv'))\n",
    "\n",
    "    # --- F. Save Label Classes ---\n",
    "    # Saving the classes is crucial for decoding predictions later\n",
    "    np.save(os.path.join(save_dir, f'label_classes_{version}.npy'), output_encoder.classes_)\n",
    "    \n",
    "    print(f\"COMPLETED: {n} features pipeline finished.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c39307",
   "metadata": {},
   "source": [
    "# Transformation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9f35ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Transformation Methods ---\n",
    "# We use the voting function to compare PCA/LDA with different components\n",
    "# and automatically select the best one based on validation accuracy.\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"STARTING FEATURE TRANSFORMATION SELECTION\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# 1. Run Voting for Transformation Methods\n",
    "# This will compare PCA and LDA with 0.99, 0.95, and 0.90 variance/components\n",
    "best_transformation, transformation_results = perform_voting_feature_transformation(\n",
    "    X_train, y_train, X_val, y_val,\n",
    "    n_components_options=[0.99, 0.95, 0.90],\n",
    "    sample_size=None,\n",
    "    file_path=preprocessing_dir,\n",
    "    version=\"transformation_comparison\"\n",
    ")\n",
    "\n",
    "if best_transformation:\n",
    "    best_method = best_transformation['method']\n",
    "    best_n_comp = best_transformation['n_components']\n",
    "    \n",
    "    print(f\"\\n[Result] Best Transformation: {best_method.upper()} with n_components={best_n_comp}\")\n",
    "    \n",
    "    # 2. Apply the Best Transformation to all datasets\n",
    "    # We need to re-run the transformation with the best parameters to get the final datasets\n",
    "    # Note: We pass X_test to get it transformed as well\n",
    "    X_train_trans, X_val_trans, X_test_trans, exec_time = perform_transformation_feature_selection(\n",
    "        X_train, y_train, X_train, X_val, X_test, # Fit on X_train\n",
    "        n_components=best_n_comp, \n",
    "        method=best_method\n",
    "    )\n",
    "    \n",
    "    # 3. Setup Directory for the best transformation\n",
    "    version = f\"{best_method.upper()}_{best_n_comp}\"\n",
    "    save_dir = os.path.join('..', 'data frames', 'main', model_name, version)\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        print(f\"[Setup] Created directory: {save_dir}\")\n",
    "        \n",
    "    # 4. Save Transformed Dataframes\n",
    "    print(f\"[Step 3] Saving best transformed dataframes to {save_dir}...\")\n",
    "    save_to_csv(X_train_trans, os.path.join(save_dir, f'X_train_{version}.csv'))\n",
    "    save_to_csv(X_val_trans, os.path.join(save_dir, f'X_val_{version}.csv'))\n",
    "    save_to_csv(X_test_trans, os.path.join(save_dir, f'X_test_{version}.csv'))\n",
    "    \n",
    "    # Save targets (unchanged)\n",
    "    save_to_csv(y_train, os.path.join(save_dir, f'y_train_{version}.csv'))\n",
    "    save_to_csv(y_val, os.path.join(save_dir, f'y_val_{version}.csv'))\n",
    "    save_to_csv(y_test, os.path.join(save_dir, f'y_test_{version}.csv'))\n",
    "    \n",
    "    # Save Label Classes\n",
    "    np.save(os.path.join(save_dir, f'label_classes_{version}.npy'), output_encoder.classes_)\n",
    "    \n",
    "    print(f\"COMPLETED: Best transformation pipeline finished.\\n\")\n",
    "else:\n",
    "    print(\"No suitable transformation method found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
